\section{Espase Probabilisé} % (fold)
\label{sec:course_1}

% section course_1 (end)
Soit $\Omega$ est \textsc{Univers} (est random ensemble).

\begin{definition}{\emph{$\sigma$ - algebra}}
	
	La famille des ensembles $\mathcal{A}$ s'appelle \textsc{$\sigma$-Algebra} si:
	\begin{enumerate}
		\item $\Omega\in \mathcal{A}$
		\item Pour tout $A\in \mathcal{A}$, $A^c\in \mathcal{A}$ ($A^C=\bar{A}$)
		\item Si $\{A_k\}^\infty_{k=1}\in \mathcal{A}:\ \cup^\infty_{k=1}A_k\in\mathcal{A}$
	\end{enumerate} 
\end{definition}


\begin{definition}{\emph{Probabilité}}
	\begin{enumerate}
		\item $\pro (\Omega)=1$
		\item Si $\{A_k\}_k^\infty$ - disjoint (pour tout $i\neq j:\ A_i\cup A_j = \emptyset$):
		$$\pro (\cup^\infty_{k=1}A_k)=\sum^\infty_{k=1}\pro (A_k)$$
	\end{enumerate}
\end{definition}

Espasce probabilisable $( \underbrace{\Omega}_\text{univers},\ 
\underbrace{ \mathcal{A} }_\text{tribu} )$.

Espase probabillisé $(\Omega,\ \mathcal{A},\ \pro )$.

\textsc{Variable Aléatoire} (random variable) est fonction measurable $X$: $$X:\Omega\rightarrow\mathbb{R}$$

\begin{diagram}
\Omega & \rTo^X & \mathbb{R} \\
\dTo<{\sigma\text{-algebre}} &  & \dTo>{\sigma\text{-algebre}} \\ 
\mathcal{A} &  &  \mathcal{B}\text{ (Borel)}
\end{diagram}

Soit $\Omega$ un ensemble. Soit $\mathcal{F}$ un famille d'ensembles de $\Omega$, qui n'est pas forcément une $\sigma$-algebre.

\begin{definition}
	On appelle $\sigma$-algebr engendrée par $\mathcal{F}$, denotée $\sigma(\mathcal{F})$ la plus petite $\sigma$-algebre que contient $\mathcal{F}$.
\end{definition}

\begin{definition}
	Borel ($\mathcal{B}$) est la $\sigma$-algebre engendrée par les intervalles ouvertes de $\mathbb{R}$ c'est-â-dire de la forme $(a,\ b),\ |a|,\ |b| < \infty$ (famile $\mathcal{F}_0$).
\end{definition}

On dit Borel ($\mathcal{B}$) est aussi $\sigma$-algebre engendrée par des intervalles de la forme $(-\infty,\ |a|],\ |a|<\infty$ (famile $\mathcal{F}_{FN}$).

\begin{remark}
	$\sigma(\mathcal{F}_0)=\sigma(\mathcal{F}_{FN})$
\end{remark}

\begin{proposition}
	Pour verifier la measurable il suffit de la tester sur une famile qui engendrée la $\sigma$-algebre de Borele.
\end{proposition}

\emph{Exercice}. (simple mais important)\\
Soit $\Omega$ un ensemble. $\mathcal{P}= \{P_1,\ P_2,\,...\,,\ P_k\}$ est une partition finit de $\Omega$, c'est-â-dire $\cup_{j=1}^k P_j=\Omega$ et $P_\alpha\cap P_\beta=\varnothing$.

\begin{enumerate}
	\item Trouve $\sigma(\mathcal{P})$.\\Réponse:
	
$\sigma(\mathcal{P})$ contient tout reunion d'elementes $\mathcal{P}$.\\
(En partiqulier si $A\in\sigma(\mathcal{P})$: $A=\cup_{k=1}^l P_{i_k}$)
	\item Trouve commont sont faites les v.a. par rapport â $\sigma{\mathcal{P}}$.\\Réponse:
	
	Consider $\Omega=\mathbb{R}$. $X(\omega)=\alpha$. $\alpha$ est l'image $\omega$. Le point  $\alpha$ est aussi un ensemble, qu'on denote $\{\alpha\}$: "singlitore" qui est un borelien. Car $X$ est measurable par rapport â $\sigma(\mathcal{P})$, $X^{-1}(\{\alpha\})=\cup P_{i_k}$.
	
	Une function measurable pour rapport à $\sigma(\mathcal{P})$ est constante par morceaux sr les éléments de la partition. 
	
	On replace $X$ avec autre object qui "approxime" $X$ est measurable par rapport â $\sigma(\mathcal{P})$.
\end{enumerate}

Espase probabilisé $(\Omega,\ \mathcal{A},\ \pro )$. $X:\Omega\rightarrow\underbrace{\mathbb{R}}_\text{Borel}$,  $X$ est v.a. 

Loi de $X$ on définir un mesure de probabilite sur ($\mathbb{R},\ \mathcal{B}$) de la maniere sivante si $B\in\mathcal{B}$: $P_X(B)=\pro (X^{-1}(B))$.

On appelle $P_X$ de \textsc{La Loi de $X$}.

$X:\Omega\rightarrow\mathbb{R}$ On pourra écrite $X$ de la maniere suivante: $X(\omega)=\sum_{k=1}^\infty x_k \ind _{A_k}(\omega)$, $A_k=\{\omega\, |\, X(\omega)\in A_k\}$. Calculer $P_X$ (la loi de $X$):

Si $B\in\mathcal{F}$, $P_X(B) = \pro (X^{-1}(B))$.

On appelle $D$ l'ensemble valiur de $X$: $D=\{x_1,\ X_2,\, ...\,x_k\, ...\}$.

$P_X(B)=P_X(B\cap D)=P_X(B\cap \cup_{k=1}^\infty\{x_k\})=P_X(\cup_{k=1}^\infty(B\cap \{x_k\}))=\sum_{k=1}^\infty P_X(B\cap \{x_k\})=\sum_{k=1}^\infty \pro (X=x_k)\delta_{\{x_k\}}(B)=\sum_{k=1}^\infty p_k \delta_{\{x_k\}}(B)$

$$\delta_a(B)=\left\{
\begin{array}{rl}
	1 & \mbox{ si } a\in B \\ 
	0 & \mbox{ si } a\notin B
\end{array}\right.$$

On introduit la measure de Dirrac:

$$\left. \begin{array}{rrl}
	X & = &\sum\limits_{k=1}^\infty x_k \ind _{A_k}\\ 
	P_x & = & \sum\limits_{k=1}^\infty p_k \delta_{\{x_k\}}\\
	P_x & = & \pro (A_k)
\end{array}\right\}\text{ v.a. discrete}$$

Exemple. (v.a. discrete)
\begin{enumerate}
	
	\item $B(n,\ p)$ dinomiale\\
Valeurs: $X=\{0,\ 1,\,...\, n\}$.
$$P_k=\pro (X=k)=C_n^k p^k (1-p)^{n-k},\ i\in\{0,\, ...\,, n\}$$
	\item Poisson $P(\lambda)$. Valeurs $X=\{0,\ 1,\ 2,\, ...\,\}$ - dénombrable.
	
	$$P_X(\{k\})=\pro (X=k)=\frac{e^{-\lambda}\lambda^k}{k!}$$ 
\end{enumerate}

\begin{rappel}
	$X:Ω->\R$ est une \texttt{variable aléatoire}
	
	$\E(X)=∫_ΩX(ω)\dd{\pro(ω)}$ --- esperance,
	$\V(X)=\E[[X-\E(X)]²]$ --- variance.
	
	Supposons $\E(X)= 0\Rightarrow \V(X)=\E(X²)$.
	
	$g(t)=t²$, $g◦X=X^2$. Si $g\circ X=X\circ g$, $g$ --- identite.
\end{rappel}

\begin{rappel}
	\texttt{Variable aléatoire} à valeurs réelle: $X:Ω->\R$. \texttt{Loi de} $X$: une measure de probabilité sur $\R$ $P_X(B)=\pro(X\dmo(B)),\ B\in\mathcal{B}$.
	
\end{rappel}

\begin{theorem}
	Soit $X:Ω->\R$ une v.a. sur l'espace probabilisé $(Ω,\mathcal{A}, \pro)$ et soit $g:\R->\R$ une fonction measurable. si l'integrale $∫_Ω g\circ X\dd{\pro}$ existe on a
	$$∫_Ωg(X(ω))\dd{\pro(ω)}=∫_\R g(t)\dd{P_X(t)}$$
\end{theorem}

\begin{examplebox}
	Supposons que $X$ est discrete...
	P1/2
\end{examplebox}

\underline{Independances}

Si $X$ et $Y$ sond independantes
$$P_{XY}(x\in A, Y\in B)=P_X(A) P_X(B)$$

Produit direct de deux measure?

Considere $S=S_1\times S_2$.

Defiltat

Di ou construit l'espase measurable $(S_1\times S_2,\ \mathcal{A}_1\times\mathcal{A}_2)$

Il existe une seule measure $\bar{\nu}$ telle que:
$$\bar{\mu}(A_1\times A_2)=\mu_1(A_1)\mu_2{A_2}$$

Cette measure $\bar{\mu}$ est le produit direct de $\mu_1$ et $\mu_1$, denote $\bar{\mu}\mu_1\times\mu_1$.

C'est-â-dire:
$$P_{XY}=P_X\times P_Y$$ % put in box.

Ex
$$\int\limits_{\mathbb{R}} f(t,u) \dif P_{XY}(t, u)\mu$$

On a besoin d'une autre quantiti; fouction de repartition de deux variables.

\begin{definition}
	Si $X$ et $Y$ sont 2 v.a. ou definit
	$$F_{xy}(u,\ v)=\pro (X\leq u, Y\leq v)$$
\end{definition}

\begin{proposition}
	Si ou connait la founction de repartition du couple $(X,Y)$ on peut calculer les fouctions de repartition marginales
	$$F_X(u)=\lim\limits_{v\rightarrow +\infty}F_{XY}(u, v)$$
	$$F_Y(v)=\lim\limits_{u\rightarrow +\infty}F_{XY}(u, v)$$
\end{proposition}
\begin{proof}
	$F_X(u)=\pro (X\leq u)=P_X((-\infty, u])$. Utilize $\mathbb{R}=\cup^\infty_{k=1}(-\infty, k]$ $(-\infty, k)$ est croissant. $\pro (X\leq u)=\pro (X\leq u, Y\in\mathbb{R})=\pro (X\leq u, Y\in\cup_{k=1}^\infty(-\infty, k])$. $F_X(u)=\pro (X\leq u)=P_X((-\infty, u])$.
\end{proof}

\begin{proposition}
	Si $X$ est $Y$ sont independant v.a. donc $F_{XY}(u, v)=F_x(U) F_Y(V)$
\end{proposition}
\begin{proof}
	...
\end{proof}

\begin{proposition}	
	Si on a: $F_{XY}=(u, v)=F_X(u)F_Y(v)$ cest-a que $X$ et $Y$ sont independante? Oui.
\end{proposition}
\begin{proof}
	$$P_{XY}(X\leq u, Y\leq v)=P_X(X\leq u)P_Y(Y\leq u)$$
	la borelien de la forme $\{(-\infty, u], |u|<\infty\}$ verifiet le properte de l'intersection firme.
\end{proof}

\begin{definition}
	La measure de lebegue dans $\mathbb{R}^2$ est la measure droduit direct des measure des lebesgue dans $\mathbb{R}$.
\end{definition}

Convention $\int f\dif \lambda(x)=\int f \dif x$.

\begin{definition}
	Un couple de v.a $(X, Y)$ a une loi conjointe $P_{XY}$ a density si pour toute borelie $B\in\mathcal{B}^{(2)}$ ($\sigma$-algebre produite), on a
	$$P_{XY}(B)=\iint\limits_{B}f_{XY}(u, v)\dif\lambda(u)\dif\lambda(v)$$. En particulier s ou a $g(u,v)\in L^1(P_{XY})$ on a:
	$$\iint\limits_{\mathbb{R}^2}g(u, v)\dif P_{XY}(u, v)=\iint g(u,v) f_{XY}(u, v)\dif \lambda(u) \dif \lambda(v)$$
\end{definition}

Questions
\begin{enumerate}
	\item Donnet les proprieties de $f_{XY}$ quand $X$ et $Y$ sont independents.
	\item Si on connait $F_{XY}(u, v)$ est-ce qu'on peut calculer les marginales $f_X(u),\ f_Y{v}$?
\end{enumerate}

\begin{proposition}{generale}
	Si on connait $f_{XY}(u, v)$ on a:
	$\begin{array}{rrl}f_X(u) & = & \int_\mathbb{R}F_{XY}(u,v)\dif v\\ f_X(v) & = & \int_\mathbb{R}F_{XY}(u,v)\dif u\end{array}$
\end{proposition}
\begin{proof}
	$F_X(t)=\lim\limits_{r\rightarrow\infty}F_{XY}(t, r)|=|$\\
	$$F_{XY}(t,r)=\pro (X\leq t, Y\leq r)=P_{XY}((-\infty, t]\times(-\infty, r])=\iint_{-\infty -\infty}^{t\ r}\dif \lambda(u) \dif \lambda(v)=F_{XY}(t,r)$$
	$|=|\lim\limits_{r\rightarrow\infty}\iint_{-\infty -\infty}^{t\ r} f_{XY}(u, v)\dif \lambda(u) \dif \lambda(v)=\lim\limits_{r\rightarrow\infty}\iint_{-\infty -\infty}^{t\ r} f_{XY}(u, v)\ind (u)\ind (v)\dif \lambda(u) \dif \lambda(v)=$\\
	\text{| Par Fubini ou sont itirer les integrales: |}\\
	$=\lim\limits_{r\rightarrow\infty}\int_{\mathbb{R}} \dif u \int_{\mathbb{R}} \dif v \ind (u)\ind (v) f_{XY}(u, v)$
	$=\lim\limits_{r\rightarrow\infty}\int_{-\infty}^t \dif u \int_{-\infty}^r \dif v  f_{XY}(u, v) =|\text{B. Levi}|=
	=\int_{\mathbb{R}} \dif u \lim\limits_{r\rightarrow\infty} \int_{\mathbb{R}} \dif v \ind (u)\ind  f_{XY}(u, v)$
	$F_X(t)=\int_{\mathbb{R}} \dif u \int_{\mathbb{R}} \dif v \ind (u)\ind  f_{XY}(u, v)$.
	
	Si $X$ est à densite $F_X(T) = \int\limits_{-\infty}^t f_X(u) \dif u$.
\end{proof}

\underline{Question} (Independantes et densités)
\begin{proposition}
	Ou a deux parties.
	\begin{enumerate}
		\item Si 2 v.a. $X$ et $Y$ admetteit, des densitis $f_X$ et $f_Y$ admetteut des densitis $f_X$ et $f_y$ et $X$ et $Y$ sont independantes, alors le couple (X, Y) ament une loi conjointe a densité et $f_{XY}=f_X f_Y$.
		\item Si le couple $(X, Y)$ adment une densite $f_{XY}$ produit de deux fouctions integrable $f_1$ et $f_2$ alors $f_1$ et $f_2$ sont les densities (à une constant pvit) de $X$ et $Y$ et $X$ et $Y$ sont indipendantes.
	\end{enumerate}
\end{proposition}

\underline{Exercise}
On a un couple de v.a. $(X, Y)$ à valuers dans $\mathbb{R}^2$ de loi conjointe:
$$P_{(XY)}(B)=\sum_{k=1}^\infty\sum_{l=1}^\infty \frac{1}{2^{k+l}}\delta_{\{k, l\}}(B)$$
Determiner la loi de $Z=\sup \{X, Y\}$.
\begin{enumerate}
	\item{question}. Determiner $P_X,\ P_Y$ oui $P_X(X=k)$.
Si $X$ et $Y$ sont discrette $\pro (X=k)=\sum\limits_j\pro (X=k,\ Y=j)$. $$P_X(\{x\}=\sum\limits_j P_{XY}(\{k, j\})$$
$$\pro (X=k)=P_X(\{k\})=\sum\limits_{j=1}^\infty \frac{1}{2^{k+j}}$$
$\pro (Z\leq k)=\pro (X\leq k, Y\leq k)=\int \ind _{[0, k]^2}(X, Y)\dif \pro =\iint \ind _{[0, k]^2} \dif P_{XY}(u, v)=\sum\limits_{i,l=1}^\infty \frac{1}{2^{i+l}}\ind _{[1, k]^2}(i, l)=\sum\limits_{i=1}^k\sum\limits_{l=1}^k\frac{1}{2^{i+l}}$
\end{enumerate}

\section{Lesson 4} % (fold)
\label{sec:lesson_4}

il fallait moutrer que si les variables aliatories $(X_1,\ X_2)$ ont une densiti $f_{X_1X_2}$ produit direct de deux fonctions $f_1$ et $f_2$ , alors a une courtant près, $f_1$ et $f_2$  sont le deuxtè de $X_1$ et $X_2$ et ces deux variables sont independantés.

L'aut partie (ex.)

Si $X_1$ et X2 sont indipendant de deuxites respectives $f_{X_1}$ et $f_{X_2}$, alors le vecteur $(X_1,\ X_2)$ a densité: $f_{X_1X_2}=f_{X_1} f_{X_2}$.

\begin{proof}
	\underline{Par Hyp}: $f_{X_1X_2}(u, v)=f_{X_1}(u) f_{X_2}(v)$. D'aurt cete on sait que en general:
	$$f_{X_1}(u)=\int_{\R}f_{X_1X_2}(u,\ v)\dd{\lambda v}$$
	$$f_{X_2}(v)=\int_{\R}f_{X_1X_2}(u,\ v)\dd{\lambda u}$$
	\underline{Objectif}: Montrer que, a une costante pres $f_1=f_{X_1}$, $f_2=f_{X_2}$. On observe que:
	$$f_{X_1}(u)=\int_{\R}f_{X_1X_2}(u,\ v)\dd{v}=f_1(u)\int_\R f_2(v)\dd{v}$$
	$$f_{X_2}(v)=\int_{\R}f_{X_1X_2}(u,\ v)\dd{u}=f_1(v)\int_\R f_1(u)\dd{u}$$
	On pultiple les deux expressions:
	$$f_{X_1}(u)f_{X_2}(v)=f_1(u)f_2(v)\int_\R f_2(v)\dd{v}\int_\R f_1(u)\dd{u}=f_1(u)f_2(v)\iint_{\R\times\R} f_2(v) f_1(u)\dd{u}\dd{v}$$
	Donc on a montré que $f_1(u)f_2(v)=f_{X_1}(u)f_{X_2}(v)$.
	\begin{remark}
		à des constants prés on pourra idéntifier $f_{X_1}$ avec $f_1$ et $f_{X_2}$ avec $f_2$. Pourtémniner: La loi du couple $(X_1, X_2)$ $P_{X_1X_2}$ ou sait que pent l'écriré. Notation Si on a ne mesure $P$ avec densite $f$ ou l'écrira coniue sa $P=f\dd{x}$, $P(A)=\int_A f\dd{x}$. $\int g\dd{f}=\int g f\dd{x}$.
	\end{remark}
		$$P_{X_1X_2}=f_{X_1X_2}(u, v)\dd{\lambda u}\dd{\lambda v}=f_1(u)f_2(v)\dd{\lambda u}\dd{\lambda v}=f_{X_1}(u)f_{X_2}(v)\dd{\lambda u}\dd{\lambda v}=P_{X_1}\times\circ P_{X_2}$$(product direct des lois marginales)

\end{proof}

\begin{proposition}
	si $X_1$ et $X_2$ sond deux v.a., cessertious suirvantes sont equivalentes:
	\begin{enumerate}
		\item $X_1$ et $X_2$ sond independantes
		\item $\forall$ fonctions $g_1$ et $g_2$ réellact positiones on a:
			$$\int g_1\circ X_1 \dot g_2\circ X_2\dd{\pro}= \int g_1\circ X_1 \dd{\pro}\int g_2\circ X_2\dd{\pro}$$
		\item Pur tout fouctions réles bornés, $g_1$ et $g_2$ on a:
			$$\int g_1\circ X_1 \dot g_2\circ X_2\dd{\pro}= \int g_1\circ X_1 d{\pro}\int g_2\circ X_2\dd{\pro}$$
	\end{enumerate}
\end{proposition}

\underline{Applications} Supposons que $g_1$ et $g_2$ sont l'identité et que $X_1$ et $X_2$ sont independantes:
	$$\mathbb{E}(X_1\dot X_2)=\mathbb{E}(X_1)\times\mathbb{E}(X_2)$$
	$$\int 1\circ X_1 \dot 2\circ X_2\dd{\pro}= \int 1\circ X_1 d{\pro}\int 2\circ X_2\dd{\pro}$$
	
\begin{examplebox}
	$X_1$ et $X_2$ indipendent $\int X_1^2 \sin X_2\dd{\pro}=\int X_1^2 \dd{\pro} \int \sin X_2\dd{\pro}$.
\end{examplebox}

\begin{proof}
	(Idée) % img 1
\end{proof}

Si $x_1$ et $X_2$ sont indepts: $\mathbb{V}(X_1+X_2)=\mathbb{V}(X_1)+\mathbb{V}(X_2)$.
$\mathbb{E}([(X_1=X_2)-\mathbb{e}(X_1+X_2)]^2)$ On developpe ce carré Ondécoucre des ceme du type $\mathbb{E}(X_1X_2)$ On utilisere cete égalité pour définir le fait que 2 variables sont \underline{dicopllies}.

\begin{examplebox}
	Sur l'espase probabilite $(\omega, \mathcal{A}, \pro)$ on considere le xouple $(X, Y)$ ave loi conjomte $P_{XY}$ à densite
	$$f_{XY}(u,v)=\alpha(1-u^2)\ind_{[0,1)}(u)v e^{-3v}\ind_{(0, +\infty)}$$
	\begin{enumerate}
		\item déterminer le valur de $\alpha$
		\item déterminer la lois marginales.
	\end{enumerate}
\end{examplebox}

\begin{examplebox}
	Sur l'espase $(\Omega,\mathcal{A},\pro)$ ou le vecteru aléatoire $(X, Y)$ de loi
	$$P_{XY}=\alpha(\mu_1+\mu_2+\mu_3)$$
	où $\alpha$ est un parametu ree et $\mu$ est une mesure à densité avec densité:
		$$f_1(u, v)=\frac{1}{u^2}e^{-v}\ind_{[1,+\infty)}(u)\ind_{[0, +\infty)}(v)$$
	$\mu_2$: mesure uniforment distribuée sur $[0,1]\times[0,1]$. $\mu_3=\delta_{\{1,1\}}+\delta{\{-1,2\}}$. Determiner $\alpha$ et le lois marginales de $X$ et de $Y$. Est que $X$ et $Y$ sont independantes?
\end{examplebox}
% section lesson_4 (end)

\begin{exercise}
		Soit $(X,Y)$ un vecteur dliatoire à veleurs dans $\R^2$.
		\begin{enumerate}
			\item suppose que le loi du couple $(X,Y)$ est connue:
			$$d_{XY}(u,v)=\lambda \rho e^{-\lambda u - \rho v}\ind_{\R^2_+}(u,v) \dd{u}\dd{v}$$
			Determiner la loi de la v.a. $W=\min\{X,Y\}$
			
			Deux méthodes (équivalentes). 1 ere méthode: $F_W(t)=\P(W\leq t)=1-\P(W>t)=1-\P(X>t,Y>t)=1-\int\limits_\Omega \ind_{(t,+\infty)}X\cdot \ind_{(t,+\infty)}Y \dd{\pro}=\iint\limits_{\R\times\R} \ind_{(t,+\infty)\times(t,+\infty)}\dd{P_{XY}(u,v)}=\iint\limits_{\R\times\R} \ind_{(t,+\infty)\times(t,+\infty)} \lambda \rho e^{-\lambda u}e^{-\rho v}\dd{u}\dd{v},\ t\geq 0$
$=1-\int_t^\infty \dd{u} \int_t^\infty \dd{v} \lambda \rho e^{-\lambda u} e^{-\rho v}=1-\lambda\int_t^\infty e^{-\lambda}\dd{u} \rho \int_t^\infty e^{-\rho v}\dd{v} = [1-e^{-(\lambda -\rho)t}]\ind_{[0,\infty]}(t)$.

On sait que:
$$F_W(t)=\int_{-\infty}^tf_W(s)\dd{s}.$$
Si on connait $f_X$, ou peut calculer $F_W$?

$F$---distribution function (function de repartition).\\
$f$---probability density function (function de density).

$F'_W(t)=(\lambda+\rho)e^{-(\lambda+\rho)t}$
Mais $F'_W=(\lambda+\rho)$ from +, but 0 from -0.		

Il y a 2 cas:\\
(i)	$t\in(-\infty,0)\ F_W(t)=0\Rightarrow f_W(t)=0$\\
(ii) $t\geq 0$ $[1-e^{(\lambda+\rho)t}]=\int_\infty^t f_W(s)\dd{s}$

Est-ce que $X$ et $Y$ sont indépendantes? Yes. $f_X\cdot f_Y$.

Méthode tris générale pour conotruire des variables aleatorias.

On cnstruit une nouvelle v.a. $g\circ X=Y$. \underline{Question} Si on connaît la loi de $X$, peut on calculer la loi de $Y$?
Ex $X$ a nue loi exp: $f_X(u)=\lambda e^{-\lambda u}$; calcules la loi de $\sqrt[2]{X}=Y$.

Couridevous une fouction test non-negative $h:\R\to\R_+$ et ou eousitere:
$$\mathbb{E}(h\circ Y)=\int_\Omega h\circ Y\dd{\pro}=\int_\Omega h\circ g\circ X \dd{P}$$
$$\int_\Omega h\circ Y\dd{\pro}=\int_\R h(v)f_Y(v)\dd{v}$$
$$==\int_\R h(g(u))\dd{P_X(u)}=\int_\R h(g(u))f_x(u)\dd{u}$$

On a: $\int_\R h(g(u))f_X(u)\dd(u)=(\mbox{Particular case})=\lambda\int_\R h(\sqrt{u})e^{-\lambda u}\dd{u}$

On pose $\sqrt{u}=v$ $\dd{v}=\frac1{2v}\dd{u}$

$==2\lambda\int_0^\infty h(v)e^{-\lambda v^2}v\dd{v}$.

Loi de $Y=\sqrt{X}$ est: $f_Y(v)=2\lambda v e^{-\lambda v^2} \ind_{[0,+\infty)}(v)$.

\underline{Deux méthod}

$\mathbb{E}(h(W))\overset{\mbox{\tiny si on l'ect, comme ca}}{=}=\int_\R h(y)f_W(y)\dd{y}$, $f_W$ la densité de $W$. $h$ -fonction test.

$\mathbb{E}(h(W))=\int_\Omega h\circ W\dd{\pro} = \int_\Omega h\circ \min(X,Y)\dd{\pro}=\iint_{\R\times\R}h(\min(u,v))\lambda e^{-\lambda u}\rho e^{-\rho v}\dd{u}\dd{v}= 
\iint\limits_{\{(u,v), u<v\}}h(u)\lambda e^{-\lambda u}\rho e^{-\rho v}\dd{u}\dd{v}+\iint\limits_{\{(u,v), u>v\}}h(u)\lambda e^{-\lambda u}\rho e^{-\rho v}\dd{u}\dd{v}=
\int_0^{+\infty}h(u)e^{-(\lambda+\rho)u}(\lambda+\rho)\dd{u}$
	
	\item 
	\end{enumerate}


\end{exercise}

On a un vecteur aliatoire $(X,Y)$ a valeurs dans $\R^2$, avec loi:
$$f_{XY}(u,v)= \frac1{4\pi} e^{-\frac u2}\ind_{\{u\geq 0\}} \ind_{[0,2\pi]}$$
Determiner loi du vecteur aliatoire $(\sqrt X \cos Y, \sqrt X \sin Y)$.

$\omega\rightarrow(X(\omega),Y(\omega))$

$$g: \left\{ \begin{array}{rcl}u&=&g_1(x,y)\\v&=&g_2(x,y)\end{array} \right.$$
$g=(g_1,g_2)$

\begin{align*}
	v(\omega)=g_1(X(\omega), Y(\omega))\\
	u(\omega)=g_2(X(\omega), Y(\omega))
\end{align*}
 U vecteur: $(g_1\circ (X,Y), g_2\circ (X,Y))$.
 
 Test fonction $h$, $h:\R^2\rightarrow \R$.

$\mathbb{E}(h\circ (X,Y))=\int h\circ (X,Y)\dd{\pro}=\iint h(g(u,v))f_{XY}(u,v)\dd{u} \dd{v}=\iint h(g_1(u,v),g_2(u,v))f_{XY}(u,v)\dd{u} \dd{v} \overset{?}{=} \int h(\alpha,\beta)f(\alpha, \beta)\dd{\alpha}\dd{\beta}$	


\section{lesson}

$(X,Y)$ 2 v.a. et euxute ou avcit une fouction vectoriélle $g=(g_1,g_2)$ $g:\R^2\rightarrow\R^2$ et on difinit 2 nouvelle v.a. $U$ et $V$ de cette façon:
$U=g_1\circ (X,Y)$, $V=g_2\circ (X,Y)$ et
$$\left\{\begin{array}{ccc}U(\omega)&=g_1(X(\omega),Y(\omega))\\V(\omega)&=g_2(X(\omega),Y(\omega))\end{array}\right.,\ \omega\in\Omega\text{ (espace des elements)}$$

%img arrows r^2

Cas particuler (Exercice)
$(X,Y)$ une couple de v.a. de loi  cougointe:;
$$f_{XY}=\frac1{4\pi}e^{-\frac u2}\ind_{u\geq 0}(u)\ind_{[0,2\pi]}(v)\dd{u}\dd{v}$$
Question: Trouver la loi du couple:
$$(\sqrt{X}\cos Y, \sqrt X\sin Y)=(U,V)$$
Sait $h:\R^2\rightarrow \R$ une fonction test non-negative.

$\E(h\circ g(X,Y))=\int_\Omega h\circ g(X,Y)\dd{\pro}=\iint\limits_{\R^2}h(g_1(x,y), g_2(x,y))f_{XY}(x,y)\dd{x} \dd{y}\overset{?}{=}\iint\limits_{\R^2}h(u,v)f_{UV}(u,v)\dd{u} \dd{v}$

$$\left\{\begin{array}{ccc}u=\sqrt x \cos y\\ v=\sqrt x \sin y\end{array}\right.$$

$$g: \left\{ \begin{array}{ccc}u&=&g_1(x,y)\\v&=&g_2(x,y)\end{array} \right.$$

$g=(g_1,g_2)$. Pour povoir effectuer un changement de variable, il faut que $g$ soiit un \underline{diffeomorphism} entre 2 ouverts.
% img omega 

$g:\mathcal O_1\rightarrow \mathcal O_2$ diffeomorphism cutu deux ouverts. Coudition equivalents pour avoir un diffeomorphism:
\begin{enumerate}
	\item $g$ est injective sur $\mathcal O_1$ à valeurs dans $\mathcal O_2$.
	\item $g$ est de classe $b^{(1)}(\mathcal O_1)$, c'est-à dire les deciver peut eller de $g$ existe tout caitunes.
	\item Le determinant de $(g\dmo)'\neq 0$ sur$\mathcal O_2$
\end{enumerate}

Nous son defini

$$g: \left\{ \begin{array}{ccc}u&=&g_1(x,y)\\v&=&g_2(x,y)\end{array} \right.\overset{\mbox{il faut inverser}}{\rightarrow}$$
$$g\dmo: \left\{ \begin{array}{ccc}x&=&\Phi_1(u,v)\\y&=&\Phi_2(u,v)\end{array} \right.$$
$\Phi=(\Phi_1,\Phi_2)$

On coustruit la invative Jacobienne (derives) de $g\dmo=\Phi$:

$$J_\Phi(u,v)=\mqty(\pdv{\Phi_1}{u}&\pdv{\Phi_1}{v}\\\pdv{\Phi_2}{u}&\pdv{\Phi_2}{v})$$
$$|\det J_\Phi (u,v)|$$

$$=\iint\limits_{g(O_1)=O_2}h(u,v)f_{XY}(\Phi_1(u,v),\Phi_2(u,v))|\det J_\Phi (u,v)|\dd{u}\dd{v}$$

Trouve le nouvelle domain d'integration.

La densiti de $(U,V)$ est donc:
$$f_{UV}(u,v)=f_{XY}(\Phi_1(u,v),\Phi_2(u,v))\cdot |\det J_\Phi(u,v)|\cdot \ind_{g(\mathcal O_1)}(u,v)$$


Continue with exercice:

$\iint_{0\ 0}^{\infty\ 2\pi} h(\sqrt x \cos y,\sqrt x \sin y)\frac 1{4\pi}e^{-\frac x2}\dd{x}\dd{y}$

$$g:\ \left\{\begin{array}{ccc}u=\sqrt x \cos y\\ v=\sqrt x \sin y\end{array}\right.$$

$\Rightarrow \Phi: \left\{\begin{array}{ccc}x=u^2+v^2 \\ y=\arctan(\frac vu) \end{array}\right.$


$=\iint\limits_{\R\times\R}=\dd u\dd v h(u,v) \frac 1{4\pi}e^{\frac{-(u^2+v^2)}2}\cdot |\det J_\Phi (u,v)|$

$$J_\Phi(u,v)=\left(\begin{array}{cc}2u&2v\\ \frac{-v}{u^2+v^2}&\frac u{u^2+v^2}\end{array}\right)$$
$\det J_\Phi (u,v)=\frac{2u^2}{u^2+v^2}+\frac{2v^2}{u^2+v^2}$

Question:
\begin{itemize}
	\item $U$ et $V$ sont independent? Oui car $f=f1\cdot f2$
	\item Lui de $U$ et $V$:
	$\frac 1{\sqrt 2\pi}e^{\frac{-(u^2+v^2)}2}$ et $\frac 1{\sqrt 2\pi}e^{\frac{-(u^2+v^2)}2}$
\end{itemize}

Exercice
Soit $(X,Y)$ une vecteur aliatoire de loi $f_{XY}(x,y)=\frac 1{2\pi}e^{-\frac{x^2+y^2}2}$. Calculer la loi de $(X+Y,Y)$.
Objectiv calcul la lua de la summe.

$$\iint_{\R^2}h(x+y, y)\frac 1{2\pi}e^{-\frac{x^2+y^2}2}\dd x\dd y$$
$$g: \left\{ \begin{array}{ccc}u&=&g_1(x,y)=x+y\\v&=&g_2(x,y)=y\end{array} \right.$$
$$\Phi: \left\{ \begin{array}{ccc}x&=&u-v\\y&=&v\end{array} \right.$$
$$\abs{\det J_\Phi (u,v)}=1$$
$$=\iint_{\R\times\R}h(u,v)\frac{1}{2\pi}e^{-\frac{(u-v)^2+v^2}{2}}\dd u\dd v$$
Densiti de $(X+Y,Y)$ est $\frac{1}{2\pi}e^{-\frac{u^2-2uv+2v^2}{2}}$.
Densiti de $(X+Y)$:
$$f_U(u)=\int_{-\infty}^\infty f_{UV}(u,v)\dd v=\frac 1{2\pi}\int_{-\infty}^\infty e^{-\frac 12(u^2-2uv+2v^2)}\dd v$$
---produit de convolution.

Si $X$ et $Y$ sont independant de loi marginal $f_X$ et $f_Y$ alors la v.a. X+Y est à densitè est $f_{X+Y}(u)=\int_\R f_Y(u)\cdot f_X(u-v)\dd v\overset{\mbox{def}}{=}f_Y\ast f_X$---produit de convolution.
